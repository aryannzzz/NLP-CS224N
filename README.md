# NLP-CS224N
Personal repository for learning Natural Language Processing following Stanford's CS224N course (Winter 2021/2023).

## Study Plan Overview

This repository contains my week-by-week study plan for completing the CS224N course. The plan covers a 12-week intensive learning schedule with lectures, assignments, readings, and practice projects.

### Course Details
- **Course**: CS224N: Natural Language Processing with Deep Learning
- **University**: Stanford
- **Duration**: 12 weeks (15-20 hours/week)
- **Estimated Total Time**: 180-240 hours
- **Course Website**: [Stanford CS224N](https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1214/)

## Weekly Breakdown

### Week 0: Prerequisites & Setup (Optional)
- Python, PyTorch, and Hugging Face setup
- Review of linear algebra, calculus, and probability
- Watch tutorial videos (Videos 19-21)

### Week 1: Word Vectors & Foundations
- **Topics**: Word embeddings, word2vec, skip-gram model
- **Assignment 1**: Introduction to Word Vectors (6%)
- **Mini-Project**: Word Analogy Explorer

### Week 2: Neural Networks & Backpropagation
- **Topics**: Backpropagation, matrix calculus, neural networks
- **Assignment 2**: word2vec Implementation (12%)

### Week 3: Dependency Parsing & RNN Foundations
- **Topics**: Syntactic structure, RNNs, language modeling
- **Assignment 3**: Dependency Parsing & Neural Networks (12%)
- **Mini-Project**: Character-Level Language Model

### Week 4: Advanced RNNs & Sequence-to-Sequence
- **Topics**: LSTM, GRU, vanishing gradients, attention mechanism
- **Focus**: Machine translation, encoder-decoder architecture

### Week 5: Neural Machine Translation Assignment
- **Assignment 4**: Neural Machine Translation (12%)
- **Topics**: Attention, subword modeling, BPE, BLEU evaluation

### Week 6: Transformers Revolution
- **Topics**: Self-attention, multi-head attention, transformer blocks
- **Key Paper**: "Attention Is All You Need"
- **Mini-Project**: Mini-Transformer from Scratch

### Week 7: Pretraining & Fine-tuning
- **Topics**: Transfer learning, BERT, GPT, masked language modeling
- **Assignment 5**: Self-Supervised Learning & Fine-tuning (12%)
- **Mini-Project**: Multi-Task Fine-tuning

### Week 8: Question Answering & Advanced Topics
- **Topics**: SQuAD, extractive QA, BiDAF, prompting, RLHF
- **Focus**: Project planning and proposal preparation

### Week 9: Natural Language Generation & Coreference
- **Topics**: Text generation, decoding strategies, coreference resolution
- **Assignment**: Project Proposal (5%)
- **Mini-Project**: Model Interpretability Study

### Week 10: Specialized Topics & Project Work
- **Topics**: Large language models, knowledge integration, multimodal learning, code generation
- **Focus**: Project implementation and baseline development

### Week 11: Ethics, Analysis & Project Milestone
- **Topics**: Bias in NLP, fairness, privacy, model interpretability
- **Assignment**: Project Milestone (5%)
- **Focus**: Progress report and preliminary results

### Week 12: Future of NLP & Final Project
- **Topics**: Open problems, research directions, career paths
- **Assignment**: Final Project Report (30%)
- **Project Summary**: Image + paragraph (3%)

## Grading Breakdown (Self-Study)

| Component | Percentage | Notes |
|-----------|-----------|-------|
| Assignment 1-5 | 54% | 5 major assignments |
| Project Proposal | 5% | 1-2 pages |
| Project Milestone | 5% | Progress report |
| Project Summary | 3% | Image + paragraph |
| Final Project Report | 30% | 8-10 pages in NeurIPS format |
| **Total** | **97%** | Adjusted for self-study |

## Key Learning Outcomes

By completing this course, I aim to:
- ✅ Understand word embeddings and their properties
- ✅ Master backpropagation and neural network training
- ✅ Implement RNNs, LSTMs, and sequence models
- ✅ Understand attention mechanisms deeply
- ✅ Build and fine-tune transformer models
- ✅ Apply NLP to real-world problems
- ✅ Read and understand NLP research papers
- ✅ Design and execute NLP projects from scratch

## Repository Structure

```
NLP-CS224N/
├── README.md                          # This file
├── .gitignore                         # Git ignore patterns
├── cs224n_study_schedule.tex          # Detailed study plan (LaTeX)
├── cs224n_study_schedule.pdf          # Compiled PDF schedule
└── week-1/                            # Week 1 materials and assignments
    ├── notes/                         # Lecture notes
    ├── assignments/                   # Assignment code
    ├── projects/                      # Practice projects
    └── readings/                      # Research papers and articles
```

## Resources Used

### Essential Blogs & Websites
- [Jay Alammar's Blog](https://jalammar.github.io/) - Visual explanations
- [The Gradient](https://thegradient.pub/) - NLP insights
- [Distill.pub](https://distill.pub/) - Interactive visualizations
- [LilLog (Lilian Weng)](https://lilianweng.github.io/) - Comprehensive guides

### Libraries & Tools
- [PyTorch](https://pytorch.org/) - Deep learning framework
- [Hugging Face Transformers](https://huggingface.co/transformers/) - Pretrained models
- [AllenNLP](https://allennlp.org/) - NLP research library
- [spaCy](https://spacy.io/) - Production NLP library

### Datasets
- SQuAD - Question answering
- CoNLL-2003 - Named entity recognition
- CNN/DailyMail - Text summarization
- WMT - Machine translation

## Progress Tracking

Track progress week by week:
- [ ] Week 0: Prerequisites
- [ ] Week 1: Word Vectors
- [ ] Week 2: Neural Networks
- [ ] Week 3: Dependency Parsing & RNN
- [ ] Week 4: Advanced RNNs
- [ ] Week 5: Neural MT
- [ ] Week 6: Transformers
- [ ] Week 7: Pretraining
- [ ] Week 8: Question Answering
- [ ] Week 9: NLG & Coreference
- [ ] Week 10: Specialized Topics
- [ ] Week 11: Ethics & Analysis
- [ ] Week 12: Final Project

## Time Commitment

Expected weekly time breakdown:
- **Lecture videos**: 3-5 hours
- **Reading papers and notes**: 4-6 hours
- **Assignments and projects**: 10-20 hours
- **Review and experimentation**: 2-4 hours
- **Total**: 15-25 hours per week

## Next Steps

1. ✅ Set up repository and study plan
2. Watch lectures and take comprehensive notes
3. Complete assignments with deep implementation
4. Build practice projects to reinforce learning
5. Read research papers critically
6. Plan and execute final project
7. Document learnings and share insights

## Notes

This is a self-paced study plan based on the official CS224N course. I'm following the curriculum week by week while adjusting for my own learning pace and interests. The plan includes both the official assignments and additional practice projects to ensure mastery of NLP concepts.

For detailed information on topics, readings, and assignments for each week, refer to `cs224n_study_schedule.pdf` or `cs224n_study_schedule.tex`.
